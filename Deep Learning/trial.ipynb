{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from data_processing import *\n",
    "import scipy.io as spio\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(y_true,y_pred):\n",
    "    C=0\n",
    "    # one-hot encoding\n",
    "    for col in range(y_true.shape[-1]):\n",
    "        y_pred[col] = y_pred[col] if y_pred[col] < 1 else 0.99999\n",
    "        y_pred[col] = y_pred[col] if y_pred[col] > 0 else 0.00001\n",
    "        C+=y_true[col]*torch.log(y_pred[col])+(1-y_true[col])*torch.log(1-y_pred[col])\n",
    "    return -C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [8, 4, 2], expected input[4, 3, 4] to have 4 channels, but got 3 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ds/lnt43mls129cb8n4b_0_fkhr0000gn/T/ipykernel_6028/2318722638.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    123\u001b[0m     )\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrajectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0moptimiser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0m_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/UCL/MRes Project/comm_centric design/Deep Learning/model/neural_network.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    301\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[0;32m--> 303\u001b[0;31m         return F.conv1d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    304\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [8, 4, 2], expected input[4, 3, 4] to have 4 channels, but got 3 channels instead"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "len_traj = 3 \n",
    "batch_size = 4\n",
    "d_obs = 2\n",
    "d_embed = 128 # embedding dimension\n",
    "n_heads = 8\n",
    "d_k = 16\n",
    "d_hidden = 16\n",
    "d_class = 4\n",
    "n_layers = 4 # Encoder内含\n",
    "trajectory = torch.rand(batch_size, len_traj, d_obs)\n",
    "\n",
    "class Embedding(nn.Module):\n",
    "    '''将轨迹序列映射到隐空间'''\n",
    "    def __init__(self, inpt_dim, embed_dim):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.fc = nn.Linear(inpt_dim, embed_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, d_k):\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "        self.d_k = d_k\n",
    "    \n",
    "    def forward(self, Q, K, V):\n",
    "        # scores : [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)] [1,8,5,5]\n",
    "        scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(self.d_k)\n",
    "        attn = nn.Softmax(dim=-1)(scores)\n",
    "        context = torch.matmul(attn, V)\n",
    "        return context, attn\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_embed, d_k, n_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.d_k = d_k\n",
    "        self.W_Q = nn.Linear(d_embed, d_k * n_heads) # d_embed,7维, d_k,16*8=128维\n",
    "        self.W_K = nn.Linear(d_embed, d_k * n_heads)\n",
    "        self.W_V = nn.Linear(d_embed, d_k * n_heads)\n",
    "        self.fc = nn.Linear(n_heads * d_k, d_embed)\n",
    "        self.layer_norm = nn.LayerNorm(d_embed)\n",
    "        self.DotProduct = ScaledDotProductAttention(d_k)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # q: [batch_size x len_q x d_model], k: [batch_size x len_k x d_model], v: [batch_size x len_k x d_model]\n",
    "        residual, batch_size = x, x.size(0) # 残差跨层连接\n",
    "        \n",
    "        # q_s = k_s = v_s: [batch_size, n_heads, len_q, d_k]\n",
    "        q_s = self.W_Q(x).view(batch_size, -1, self.n_heads, self.d_k).transpose(1,2)\n",
    "        k_s = self.W_K(x).view(batch_size, -1, self.n_heads, self.d_k).transpose(1,2)\n",
    "        v_s = self.W_V(x).view(batch_size, -1, self.n_heads, self.d_k).transpose(1,2)\n",
    "        \n",
    "        # context: [batch_size, n_heads, len_q, d_k]\n",
    "        # attn: [batch_size, n_heads, len_q(=len_k), len_k(=len_q)]\n",
    "        context, attn = self.DotProduct(q_s, k_s, v_s) # context是attn✖V\n",
    "        # contiguous()的功能类似deepcopy\n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.n_heads * self.d_k) # context: [batch_size x len_q x n_heads * d_k] 最后一个维度是将8个head concat起来，维度依然512\n",
    "        \n",
    "        output = self.fc(context) # [batch_size, len_q, d_embed]\n",
    "        return self.layer_norm(output + residual), attn # output: [batch_size, len_q, d_model]\n",
    "\n",
    "class PoswiseFeedForwardNet(nn.Module):\n",
    "    # 该模块也可用linear+ReLU实现\n",
    "    def __init__(self, d_embed, d_hidden):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=d_embed, out_channels=d_hidden, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=d_hidden, out_channels=d_embed, kernel_size=1)\n",
    "        self.layer_norm = nn.LayerNorm(d_embed)\n",
    "    def forward(self, x):\n",
    "        residual = x # [batch_size, len_q, d_model]\n",
    "        x = nn.ReLU()(self.conv1(x.transpose(1, 2)))\n",
    "        x = self.conv2(x).transpose(1, 2)\n",
    "        return self.layer_norm(x + residual)\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_embed, d_k, n_heads, d_hidden):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.MultiHeadAttention = MultiHeadAttention(d_embed, d_k, n_heads)\n",
    "        self.PoswiseFeedForwardNet = PoswiseFeedForwardNet(d_embed, d_hidden)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, attn = self.MultiHeadAttention(x) # x to same Q,K,V\n",
    "        x = self.PoswiseFeedForwardNet(x) # x: [batch_size, len_q, d_embed]\n",
    "        return x, attn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    '''\n",
    "    using transformer encoder to classify sequential data\n",
    "    '''\n",
    "    def __init__(self, d_obs, d_embed, d_class, d_k, d_hidden, n_heads, n_layers):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = Embedding(inpt_dim=d_obs, embed_dim=d_embed) # state dimension，embedding dimension\n",
    "        self.layers = nn.ModuleList([EncoderLayer(d_embed, d_k, n_heads, d_hidden) for _ in range(n_layers)])\n",
    "        self.fc = nn.Linear(d_embed, d_class)\n",
    "\n",
    "    def forward(self, x): # enc_inputs : [batch_size x source_len]\n",
    "        y = self.embedding(x)\n",
    "        attentions = []\n",
    "        for layer in self.layers:\n",
    "            y, attention = layer(y)\n",
    "            attentions.append(attention)\n",
    "\n",
    "        out = F.log_softmax(self.fc(y), dim=-1)\n",
    "        return out, attentions\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    from model.neural_network import LSTM_net\n",
    "    # encoder = Encoder(d_obs, d_embed, d_class, d_k, d_hidden, n_heads, n_layers)\n",
    "    encoder = LSTM_net()\n",
    "    trajectory = torch.rand(batch_size, len_traj, d_obs, dtype=torch.float32)\n",
    "    shape = torch.randint(high = 4, size = (4, 3))\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    optimiser = torch.optim.Adam(\n",
    "        encoder.parameters(),\n",
    "        lr = 0.001,\n",
    "        weight_decay=0.0001\n",
    "    )\n",
    "    for _ in range(10):\n",
    "        pred = encoder(trajectory)\n",
    "        optimiser.zero_grad()\n",
    "        _loss = loss(pred, shape)\n",
    "        _loss.backward()\n",
    "        optimiser.step()\n",
    "        print (f'{_loss.detach():.2f}')\n",
    "\n",
    "    '''\n",
    "    from torchinfo import summary\n",
    "    summary(encoder, (batch_size, len_traj, d_obs))\n",
    "    print(context.shape, attn[0].shape)\n",
    "    '''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.9983, -0.2701,  0.0599]]])\n",
      "tensor([[[-0.6897, -0.0663, -0.4248]]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 1, 3)\n",
    "print (x)\n",
    "_x = nn.Linear(3, 3)\n",
    "\n",
    "x = _x(x)\n",
    "print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 2, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0:6].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
