{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping = {\n",
    "#     0: 0.707+0.707j,\n",
    "#     1: 0.707-0.707j,\n",
    "#     2: -0.707+0.707j,\n",
    "#     3: -0.707-0.707j\n",
    "# }\n",
    "# Cluster = 200\n",
    "\n",
    "# from matplotlib import pyplot as plt\n",
    "# Nr = 4\n",
    "\n",
    "\n",
    "# def evaluateSincPulse(t):\n",
    "#     if t == 0:\n",
    "#         pulseValue = 1.0\n",
    "#     else:\n",
    "#         pulseValue = np.sin(np.pi * t) / (np.pi * t)\n",
    "#     return pulseValue\n",
    "# def symbol_clusterGen(Nr, Cluster, num_training_samples):\n",
    "#     y = np.zeros(shape = (num_training_samples, Nr, Cluster), dtype = complex)\n",
    "#     y_n = np.zeros(shape = (num_training_samples, Nr, Cluster), dtype = complex)\n",
    "#     x = np.zeros(shape = (num_training_samples, Cluster, 1), dtype = complex)\n",
    "#     x_map = np.zeros(shape = (num_training_samples, Cluster))\n",
    "    \n",
    "#     for sample_cnt in range (num_training_samples):\n",
    "#         h = np.ones(shape = (Nr, 1), dtype=complex) # h is certain for each sample\n",
    "#         signal = np.random.randint(low = 0, high = 4, size = (Cluster, 1))\n",
    "#         x_map[sample_cnt] = signal.squeeze()\n",
    "#         x[sample_cnt] = np.expand_dims(\n",
    "#             np.array(\n",
    "#                 [mapping[int(_s)] for _s in signal]\n",
    "#             ),\n",
    "#             1 \n",
    "#         ) \n",
    "\n",
    "#         for i in range (Nr):\n",
    "#             a = np.random.randn(1) + 1j * np.random.randn(1)\n",
    "#             phase = np.random.uniform(0, np.pi)\n",
    "#             delay = 1e-6 * np.random.randn()\n",
    "#             h[i] = a * np.exp(1j * phase) * evaluateSincPulse(delay)\n",
    "#             y[sample_cnt, i, :] = np.squeeze(h[i] * signal)\n",
    "#             y_n[sample_cnt, i, :] = y[sample_cnt, i, :] + 0.01 * (np.random.randn(Cluster,) + 1j * np.random.randn(Cluster,))\n",
    "\n",
    "#     return x_map, y, y_n\n",
    "\n",
    "# training_samples = 4000 # 4000 channel states\n",
    "# Nr = 4\n",
    "# cluster = 200\n",
    "# x, y, y_n = symbol_clusterGen(Nr, cluster, training_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 200, 16)\n",
      "(4000, 200, 16, 4)\n",
      "training data shape: (3900, 200, 4, 2)\n",
      "training label shape(3900, 200)\n",
      "For Epoch 1: ------------------\n",
      "    - - training step 1 - -\n",
      "   average accuracy for training is: 0.46\n",
      "    - - training step 2 - -\n",
      "   average accuracy for training is: 0.73\n",
      "    - - training step 3 - -\n",
      "   average accuracy for training is: 0.73\n",
      "    - - training step 4 - -\n",
      "   average accuracy for training is: 0.69\n",
      "    - - training step 5 - -\n",
      "   average accuracy for training is: 0.75\n",
      "    - - training step 6 - -\n",
      "   average accuracy for training is: 0.79\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ds/lnt43mls129cb8n4b_0_fkhr0000gn/T/ipykernel_1870/4012228471.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0moptimiser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0m_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0m_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0moptimiser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;31m# loss_sample += _loss.item()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from data_processing import *\n",
    "import scipy.io as spio\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "Nr = 4\n",
    "carrier_num = 16\n",
    "symbol_num = 200\n",
    "channel_num = 4000\n",
    "\n",
    "def cross_entropy(y_true,y_pred):\n",
    "    C=0\n",
    "    # one-hot encoding\n",
    "    for col in range(y_true.shape[-1]):\n",
    "        y_pred[col] = y_pred[col] if y_pred[col] < 1 else 0.99999\n",
    "        y_pred[col] = y_pred[col] if y_pred[col] > 0 else 0.00001\n",
    "        C+=y_true[col]*torch.log(y_pred[col])+(1-y_true[col])*torch.log(1-y_pred[col])\n",
    "    return -C\n",
    "_channel = {}\n",
    "_tau = list()\n",
    "_fdoppler = list()\n",
    "_Txsteering = list()\n",
    "_Rxsteering = list()\n",
    "_x = list()\n",
    "_y = list()\n",
    "_y_norm = list()\n",
    "h = list()\n",
    "\n",
    "for i in range(1, channel_num+1):\n",
    "    path = f'./test_data/ISAC_QPSK_OFDM_{i}.mat'\n",
    "    data = spio.loadmat(path)\n",
    "    _tau.append(\n",
    "        data['ISAC_data']['channel'][0][0]['time_delay'][0][0][0]\n",
    "    )\n",
    "    _fdoppler.append(\n",
    "        data['ISAC_data']['channel'][0][0]['f_doppler'][0][0][0]\n",
    "    )\n",
    "    _Txsteering.append(\n",
    "        data['ISAC_data']['channel'][0][0]['Tx_steeringangle'][0][0][0]\n",
    "    )\n",
    "    _Rxsteering.append(\n",
    "        data['ISAC_data']['channel'][0][0]['Rx_steeringangle'][0][0][0]\n",
    "    )\n",
    "    _x.append(\n",
    "        data['ISAC_data']['x'][0][0]\n",
    "    )\n",
    "    _y.append(\n",
    "        data['ISAC_data']['y'][0][0]\n",
    "    )\n",
    "    _y_norm.append(\n",
    "        data['ISAC_data']['y_norm'][0][0]\n",
    "    )\n",
    "    h.append(\n",
    "        data['ISAC_data']['h'][0][0]\n",
    "    )\n",
    "\n",
    "_channel['time_delay'] = _tau\n",
    "_channel['doppler_shift'] = _fdoppler\n",
    "_channel['_Txsteering'] = _Txsteering\n",
    "_channel['_Rxsteering'] = _Rxsteering\n",
    "\n",
    "x, _, y_norm, h = np.array(_x), np.array(_y), np.array(_y_norm), np.array(h)\n",
    "print (x.shape)\n",
    "print (y_norm.shape)\n",
    "def mapping_qpsk (\n",
    "    data\n",
    "):\n",
    "    _real = np.real(data)\n",
    "    _imag = np.imag(data)\n",
    "\n",
    "    if _real > 0 and _imag > 0:\n",
    "        return 0\n",
    "    if _real > 0 and _imag < 0:\n",
    "        return 1\n",
    "    if _real < 0 and _imag > 0:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "# take the first carrier as an example\n",
    "\n",
    "y_lstm_isac = np.zeros(shape = (carrier_num, channel_num, symbol_num, Nr, 2))\n",
    "label_isac = np.zeros(shape = (carrier_num, channel_num, symbol_num))\n",
    "for n in range (carrier_num):\n",
    "    for i in range (channel_num):\n",
    "        for j in range (symbol_num):\n",
    "            label_isac[n, i, j] = mapping_qpsk (\n",
    "                x[i, j, n]\n",
    "            )\n",
    "            for k in range (Nr):\n",
    "                y_lstm_isac[n, i, j, k] = np.array(\n",
    "                    [\n",
    "                        np.real(y_norm[i, j, n, k]),\n",
    "                        np.imag(y_norm[i, j, n, k]),\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "y_carrier0, label_carrier0 = y_lstm_isac[0], label_isac[0]\n",
    "\n",
    "y_train = y_carrier0[0:3900]\n",
    "y_test = y_carrier0[3900:]\n",
    "\n",
    "label_train = label_carrier0[0:3900]\n",
    "label_test = label_carrier0[3900:]\n",
    "print (f'training data shape: {y_train.shape}')\n",
    "print (f'training label shape{label_train.shape}')\n",
    "\n",
    "\n",
    "# # change y into real + imag\n",
    "# y_lstm = np.zeros(shape=(training_samples, Nr, cluster, 2))\n",
    "# y_lstm_n = np.zeros(shape = (training_samples, Nr, cluster, 2))\n",
    "# for i in range (training_samples):\n",
    "#     for j in range (Nr):\n",
    "#         for k in range (cluster):\n",
    "#             y_lstm[i, j, k] = np.array(\n",
    "#                 [\n",
    "#                     np.real(y[i, j, k]),\n",
    "#                     np.imag(y[i, j, k])\n",
    "#                 ]\n",
    "#             )\n",
    "#             y_lstm_n[i, j, k] = np.array(\n",
    "#                 [\n",
    "#                     np.real(y_n[i, j, k]), \n",
    "#                     np.imag(y_n[i, j, k])\n",
    "#                 ]\n",
    "#             )\n",
    "\n",
    "# print (y_lstm.shape)\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size, hidden_size, bidirectional=True, num_layers = 3\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes) # times 2 because of bidirection\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq_len, batch_size, _ = x.size()\n",
    "        h0 = torch.zeros(2*self.lstm.num_layers, batch_size, self.hidden_size).to(x.device) # 2 for bidirection \n",
    "        c0 = torch.zeros(2*self.lstm.num_layers, batch_size, self.hidden_size).to(x.device)\n",
    "\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "\n",
    "        return out\n",
    "\n",
    "# Parameters\n",
    "input_size = 2 # input size for each LSTM cell (complex numbers)\n",
    "hidden_size = 20 # hidden state size for LSTM cell\n",
    "num_classes = 4 # number of classes for classification\n",
    "\n",
    "# Instantiate the model\n",
    "model = BiLSTM(input_size, hidden_size, num_classes)\n",
    "# y_samples = torch.tensor(y_lstm_n, dtype = torch.float32).permute(0, 2, 1, 3)\n",
    "# label = torch.tensor(x, dtype = torch.long)\n",
    "# Example input: three sequences, each sequence is 4 complex numbers (each represented as a 2D vector)\n",
    "# The dimensions are (sequence length, batch size, input size)\n",
    "# x = torch.randn(30, 4, input_size)\n",
    "# Forward pass\n",
    "\n",
    "\n",
    "y_train = torch.tensor(\n",
    "    y_train,\n",
    "    dtype = torch.float32\n",
    ")\n",
    "\n",
    "label_train = torch.tensor(\n",
    "    label_train,\n",
    "    dtype = torch.long\n",
    ")\n",
    "\n",
    "optimiser = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr = 0.001,\n",
    "    weight_decay = 0.0001,\n",
    ")\n",
    "loss = nn.CrossEntropyLoss()\n",
    "import hiddenlayer as hl\n",
    "\n",
    "canvasl = hl.Canvas()\n",
    "historyl = hl.History()\n",
    "window_size = 40\n",
    "train_cnt = 0\n",
    "acc_train_list = list()\n",
    "\n",
    "for epoch in range (100):\n",
    "\n",
    "    print (f'For Epoch {epoch+1}: ------------------')\n",
    "    for _y_train, _label_train in zip(\n",
    "        y_train, label_train\n",
    "    ):\n",
    "        train_cnt += 1\n",
    "        acc_train = 0\n",
    "        acc_num_train = 0 # same for training and test\n",
    "        # loss_sample = 0\n",
    "        # loss_num_sample = 0\n",
    "        for cnt in range (symbol_num - window_size + 1):\n",
    "            model.train() # train with y_train\n",
    "            X = _y_train[cnt:cnt + window_size]\n",
    "            Y = _label_train[cnt: cnt + window_size]\n",
    "            out = model(X)\n",
    "\n",
    "            # acc for each sample\n",
    "            _, predicted = torch.max(out, 1)\n",
    "            acc_train = acc_train + (predicted == Y).sum().item()\n",
    "            acc_num_train += window_size\n",
    "\n",
    "            # backward propagation\n",
    "            optimiser.zero_grad()\n",
    "            _loss = loss(out, Y)\n",
    "            _loss.backward()\n",
    "            optimiser.step()\n",
    "            # loss_sample += _loss.item()\n",
    "            # loss_num_sample += 1\n",
    "\n",
    "        acc_train_list.append(acc_train / acc_num_train)\n",
    "\n",
    "        # print (f'loss for the sample {train_cnt} is: {loss_sample / loss_num_sample:.2f}')\n",
    "\n",
    "        '''record acc for train and test        \n",
    "        '''\n",
    "\n",
    "        acc_train_av = sum(acc_train_list) / len(acc_train_list)\n",
    "        print (f'    - - training step {train_cnt} - -')\n",
    "        print (f'   average accuracy for training is: {acc_train_av:.2f}')\n",
    "        historyl.log(\n",
    "            train_cnt,\n",
    "            acc_train_average = acc_train_av\n",
    "        )\n",
    "\n",
    "        # with canvasl:\n",
    "        #     canvasl.draw_plot(\n",
    "        #         historyl['acc_train_average']\n",
    "        #     )\n",
    "    # from matplotlib import pyplot as plt\n",
    "    # plt.savefig(f'./epoch{epoch}.png')\n",
    "torch.save(model.state_dict(), './symbol_detection.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
